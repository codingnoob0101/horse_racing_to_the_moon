{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "844093de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be13ea99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/horses_data/horses.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ad8095a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraping_races(df):\n",
    "\n",
    "    hrefs = df['links'].tolist()\n",
    "\n",
    "    # Initiate header and rows for storage\n",
    "    header = None\n",
    "    rows = []\n",
    "\n",
    "    for href in hrefs:\n",
    "        full_url = href + '&Option=1'\n",
    "\n",
    "        try:\n",
    "            response = requests.get(full_url, timeout = 10)\n",
    "        except Exception as e:\n",
    "            print(f'Request exception for {full_url}: {str(e)}')\n",
    "            continue\n",
    "\n",
    "        match = re.search(r'([A-Z]\\d{3})$', href)\n",
    "        horse_id = match.group(1) if match else None\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "            # find origin and age\n",
    "            origin_label = soup.find('td', string = lambda text : text and 'Country of Origin' in text)\n",
    "            if origin_label:\n",
    "                origin_info = origin_label.find_next().find_next().get_text(strip = True)\n",
    "            else:\n",
    "                origin_info = 'na'\n",
    "\n",
    "            # find colour and sex\n",
    "            colour_label = soup.find('td', string = lambda text : text and 'Colour / Sex' in text)\n",
    "            if colour_label:\n",
    "                colour_info = colour_label.find_next().find_next().get_text(strip = True)\n",
    "            else:\n",
    "                colour_info = 'na'\n",
    "\n",
    "            # find import type\n",
    "            import_label = soup.find('td', string = lambda text : text and 'Import Type' in text)\n",
    "            if import_label:\n",
    "                import_info = import_label.find_next().find_next().get_text(strip = True)\n",
    "            else:\n",
    "                import_info = 'na'\n",
    "\n",
    "            # find sire\n",
    "            sire_label = soup.find('td', string = lambda text : text and 'Sire' in text)\n",
    "            if sire_label:\n",
    "                sire_info = sire_label.find_next().find_next().get_text(strip = True)\n",
    "            else:\n",
    "                sire_info = 'na'\n",
    "\n",
    "            # find dam\n",
    "            dam_label = soup.find('td', string = lambda text : text and 'Dam' in text)\n",
    "            if dam_label:\n",
    "                dam_info = dam_label.find_next().find_next().get_text(strip = True)\n",
    "            else:\n",
    "                dam_info = 'na'\n",
    "\n",
    "            # find dam's sire\n",
    "            dam_sire_label = soup.find('td', string = lambda text : text and 'Dam\\'s Sire' in text)\n",
    "            if dam_sire_label:\n",
    "                dam_sire_info = dam_sire_label.find_next().find_next().get_text(strip = True)\n",
    "            else:\n",
    "                dam_sire_info = 'na'\n",
    "            \n",
    "            # find horse per race info\n",
    "            horse_table = soup.find('table', class_='bigborder')\n",
    "            if horse_table:\n",
    "                if header is None:\n",
    "                    header_row = horse_table.find('tr')\n",
    "                    header = [th.get_text(strip=True) for th in header_row.find_all('td')]\n",
    "                    header = header[:-1]\n",
    "                    header.append('Horse_id')\n",
    "                    header.append('Origin / Age')\n",
    "                    header.append('Colour / Sex')\n",
    "                    header.append('Import type')\n",
    "                    header.append('Sire')\n",
    "                    header.append('Dam')\n",
    "                    header.append('Dam sire')\n",
    "\n",
    "                for tr in horse_table.find_all('tr')[1:]:\n",
    "                    cols = [td.get_text(strip=True) for td in tr.find_all('td')]\n",
    "\n",
    "                    if all(not col.strip() for col in cols):\n",
    "                        continue\n",
    "                    first_col = cols[0].strip()\n",
    "                    if 'Season' in first_col or first_col == 'Overseas':\n",
    "                        continue\n",
    "\n",
    "                    # append all info into the rows \n",
    "                    cols = cols[:-2]\n",
    "                    cols.append(horse_id)\n",
    "                    cols.append(origin_info)\n",
    "                    cols.append(colour_info)\n",
    "                    cols.append(import_info)\n",
    "                    cols.append(sire_info)\n",
    "                    cols.append(dam_info)\n",
    "                    cols.append(dam_sire_info)\n",
    "                    rows.append(cols)\n",
    "            else:\n",
    "                print(f'Table not found in {full_url}')\n",
    "\n",
    "\n",
    "        else:\n",
    "            print(f\"Failed to retrieve {full_url}\")\n",
    "\n",
    "    if not header:\n",
    "        raise RuntimeError(\"No data table header found! Check the structure of the page.\")\n",
    "\n",
    "    df = pd.DataFrame(rows, columns=header)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1f9daf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "race_df = scraping_races(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69b2bb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = '../data/race_data/'\n",
    "output_path = os.path.join(output_dir, 'race_data.csv')\n",
    "\n",
    "os.makedirs(output_dir, exist_ok = True)\n",
    "\n",
    "race_df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6445bead",
   "metadata": {},
   "source": [
    "Date of some horses are not in the same format. need to correct further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4c5f6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scraping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
