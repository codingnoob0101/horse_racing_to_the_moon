{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85779399",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostRanker, Pool\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c62061d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca491bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/cleaned_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a243304",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Rtg.'] = pd.to_numeric(df['Rtg.'], errors = 'coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7397c833",
   "metadata": {},
   "source": [
    "# Utility function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b578232",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_cardinality(series, min_freq = 10):\n",
    "    counts = series.value_counts()\n",
    "    rare = counts[counts < min_freq].index\n",
    "    return series.apply(lambda x: 'unknown' if x in rare else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee9ea81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_placing(group):\n",
    "    finish_mask = group['Pla.'].astype(str).str.isdigit()\n",
    "    max_rank = group.loc[finish_mask, 'Pla.'].astype(int).max()\n",
    "    return group['Pla.'].apply(lambda x: int(x) if str(x).isdigit() else max_rank + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f899db1d",
   "metadata": {},
   "source": [
    "# Approach 1 (training with all variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a04b4ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5a98bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1[~df1['Pla.'].isin(['UR', 'FE', 'TNP', 'PU', 'DNF', 'DISQ'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4df9bb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define target and groupings\n",
    "target = 'Pla.'\n",
    "group_col = 'race_index'\n",
    "\n",
    "# define categorical variables\n",
    "categorical_cols = [\n",
    "    'Dist.', 'track_condition', 'RaceClass', 'gate_position', 'Trainer', 'Jockey', 'Import type', 'Sire', 'Dam', 'Dam sire', 'rc', 'track', 'course', 'origin', 'age', 'colour', 'sex'\n",
    "]\n",
    "\n",
    "# define numerical variables\n",
    "numerical_cols = [\n",
    "    'Rtg.', 'Win Odds', 'Act.Wt', 'Declar.Horse Wt.'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b136b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# missingness indicator for 'age'\n",
    "df1['age_missing'] = df1['age'].isnull().astype(int)\n",
    "\n",
    "# impute age with median\n",
    "age_median = df1['age'].median()\n",
    "df1['age'] = df1['age'].fillna(age_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5270c815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing categoricals with 'unknown'\n",
    "for col in categorical_cols:\n",
    "    df1[col] = df1[col].fillna('unknown')\n",
    "\n",
    "# cardinality of the categories being reduced\n",
    "for col in categorical_cols:\n",
    "    df1[col] = reduce_cardinality(df1[col])\n",
    "\n",
    "for col in categorical_cols:\n",
    "    df1[col] = df1[col].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b335151c",
   "metadata": {},
   "source": [
    "cardinality in Trainer, Jockey, Sire, Dam, Dam sire, and course reduced "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b45b220b",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols_updated = ['age_missing']\n",
    "\n",
    "for col in numerical_cols_updated:\n",
    "    df1[col] = pd.to_numeric(df1[col], errors = 'coerce').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa4d04d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the features, target and groups\n",
    "X = df1[categorical_cols + numerical_cols_updated]\n",
    "y = pd.to_numeric(df1[target], errors = 'coerce') # ensure target is int\n",
    "groups = df1[group_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4c1d540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split by race index for train and test sets\n",
    "unique_races = groups.unique()\n",
    "train_races, test_races = train_test_split(unique_races, test_size = 0.2, random_state = 42)\n",
    "\n",
    "train_mask = groups.isin(train_races)\n",
    "test_mask = groups.isin(test_races)\n",
    "\n",
    "X_train, y_train, group_train = X[train_mask], y[train_mask], groups[train_mask]\n",
    "X_test, y_test, group_test = X[test_mask], y[test_mask], groups[test_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e0be44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by group_id for requirements\n",
    "train_sorted_idx = group_train.argsort()\n",
    "X_train = X_train.iloc[train_sorted_idx]\n",
    "y_train = y_train.iloc[train_sorted_idx]\n",
    "group_train = group_train.iloc[train_sorted_idx]\n",
    "\n",
    "test_sorted_idx = group_test.argsort()\n",
    "X_test = X_test.iloc[test_sorted_idx]\n",
    "y_test = y_test.iloc[test_sorted_idx]\n",
    "group_test = group_test.iloc[test_sorted_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc5447f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pool = Pool(\n",
    "    data = X_train,\n",
    "    label = y_train,\n",
    "    group_id = group_train,\n",
    "    cat_features = categorical_cols\n",
    ")\n",
    "\n",
    "test_pool = Pool(\n",
    "    data = X_test,\n",
    "    label = y_test,\n",
    "    group_id = group_test,\n",
    "    cat_features = categorical_cols\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d06d5d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train CatBoost ranking model\n",
    "model = CatBoostRanker(\n",
    "    iterations=1000,\n",
    "    learning_rate=0.02,\n",
    "    depth=3,\n",
    "    loss_function='YetiRank',\n",
    "    eval_metric='NDCG',\n",
    "    early_stopping_rounds=50,\n",
    "    random_seed=42,\n",
    "    verbose=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72d6c3e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groupwise loss function. OneHotMaxSize set to 10\n",
      "0:\ttest: 0.8461919\tbest: 0.8461919 (0)\ttotal: 81.7ms\tremaining: 1m 21s\n",
      "100:\ttest: 0.9025298\tbest: 0.9026374 (98)\ttotal: 2.06s\tremaining: 18.3s\n",
      "200:\ttest: 0.9066555\tbest: 0.9066555 (200)\ttotal: 4.14s\tremaining: 16.4s\n",
      "300:\ttest: 0.9092138\tbest: 0.9092199 (299)\ttotal: 6.26s\tremaining: 14.5s\n",
      "400:\ttest: 0.9105801\tbest: 0.9105969 (392)\ttotal: 8.39s\tremaining: 12.5s\n",
      "500:\ttest: 0.9108325\tbest: 0.9109858 (491)\ttotal: 10.5s\tremaining: 10.5s\n",
      "600:\ttest: 0.9112805\tbest: 0.9113739 (588)\ttotal: 12.6s\tremaining: 8.38s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.911504219\n",
      "bestIteration = 607\n",
      "\n",
      "Shrink model to first 608 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRanker at 0x112900ec0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_pool, eval_set=test_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc80a503",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = model.predict(X_test)\n",
    "\n",
    "# Compute predicted ranks within each group (race)\n",
    "test_results = X_test.copy()\n",
    "test_results['true_pla'] = y_test\n",
    "test_results['pred_score'] = test_preds\n",
    "test_results['race_index'] = group_test\n",
    "\n",
    "test_results['pred_rank'] = test_results.groupby('race_index')['pred_score'].rank(ascending=False, method='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "86309260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Spearman rank correlation on test races: -0.4465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rn/zdwl9_vx4yz5r87jv7jnztdh0000gn/T/ipykernel_6647/1274675035.py:7: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  spearman_scores = test_results.groupby('race_index').apply(race_spearman)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate using Spearman rank correlation per race\n",
    "def race_spearman(group):\n",
    "    if len(group) <= 1:\n",
    "        return np.nan\n",
    "    return spearmanr(group['true_pla'], group['pred_rank']).correlation\n",
    "\n",
    "spearman_scores = test_results.groupby('race_index').apply(race_spearman)\n",
    "mean_spearman = spearman_scores.dropna().mean()\n",
    "print(f'Mean Spearman rank correlation on test races: {mean_spearman:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2892f0e1",
   "metadata": {},
   "source": [
    "# Updated approach (include unfinished horses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "343d7a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c974eefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode placing including unfinished horses with large numbers\n",
    "def encode_placing(group):  \n",
    "    finish_mask = group['Pla.'].astype(str).str.isdigit()\n",
    "    max_rank = group.loc[finish_mask, 'Pla.'].astype(int).max()\n",
    "    return group['Pla.'].apply(lambda x: int(x) if str(x).isdigit() else max_rank + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "233db8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define target and groupings\n",
    "target = 'Pla.'\n",
    "group_col = 'race_index'\n",
    "\n",
    "# define categorical variables\n",
    "categorical_cols = [\n",
    "    'Dist.', 'track_condition', 'RaceClass', 'gate_position', 'Trainer', 'Jockey', 'Import type', 'Sire', 'Dam', 'Dam sire', 'rc', 'track', 'course', 'origin', 'age', 'colour', 'sex'\n",
    "]\n",
    "\n",
    "# define numerical variables\n",
    "numerical_cols = [\n",
    "    'Rtg.', 'Win Odds', 'Act.Wt.', 'Declar.Horse Wt.'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4a9ef8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply encoding for places (including unfinished horses)\n",
    "df2 [target] = encode_placing(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6717bab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "unique_races = df2[group_col].unique()\n",
    "\n",
    "# split the race id for masking\n",
    "train_races, test_races = train_test_split(unique_races, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "93201d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define mask of trianing and testing\n",
    "train_mask = df2[group_col].isin(train_races)\n",
    "test_mask = df2[group_col].isin(test_races)\n",
    "\n",
    "# training and testing set\n",
    "df2_train = df2.loc[train_mask].copy()\n",
    "df2_test = df2.loc[test_mask].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c0f88399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# median imputer for numerical variables\n",
    "num_imputer = SimpleImputer(strategy = 'median')\n",
    "df2_train[numerical_cols] = num_imputer.fit_transform(df2_train[numerical_cols])\n",
    "df2_test[numerical_cols] = num_imputer.transform(df2_test[numerical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "381d5794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing with 'unknown' for categorical\n",
    "for col in categorical_cols:\n",
    "    df2_train[col] = df2_train[col].astype(str).fillna('unknown')\n",
    "    df2_test[col] = df2_test[col].astype(str).fillna('unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c99e21bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defind the x and y for train and test\n",
    "X_train = df2_train[categorical_cols + numerical_cols]\n",
    "y_train = df2_train[target]\n",
    "groups_train = df2_train[group_col]\n",
    "\n",
    "X_test = df2_test[categorical_cols + numerical_cols]\n",
    "y_test = df2_test[target]\n",
    "groups_test = df2_test[group_col]\n",
    "\n",
    "# sort the data according to group col\n",
    "train_sorted_idx = groups_train.argsort()\n",
    "X_train = X_train.iloc[train_sorted_idx]\n",
    "y_train = y_train.iloc[train_sorted_idx]\n",
    "groups_train = groups_train.iloc[train_sorted_idx]\n",
    "\n",
    "test_sorted_idx = groups_test.argsort()\n",
    "X_test = X_test.iloc[test_sorted_idx]\n",
    "y_test = y_test.iloc[test_sorted_idx]\n",
    "groups_test = groups_test.iloc[test_sorted_idx]\n",
    "\n",
    "\n",
    "train_pool = Pool(\n",
    "    data=X_train,\n",
    "    label=y_train,\n",
    "    group_id=groups_train,\n",
    "    cat_features=categorical_cols\n",
    ")\n",
    "\n",
    "test_pool = Pool(\n",
    "    data=X_test,\n",
    "    label=y_test,\n",
    "    group_id=groups_test,\n",
    "    cat_features=categorical_cols\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "62be2241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groupwise loss function. OneHotMaxSize set to 10\n",
      "0:\ttest: 0.7476582\tbest: 0.7476582 (0)\ttotal: 38.3ms\tremaining: 38.3s\n",
      "100:\ttest: 0.8186548\tbest: 0.8190583 (93)\ttotal: 2.84s\tremaining: 25.3s\n",
      "200:\ttest: 0.8226846\tbest: 0.8228631 (181)\ttotal: 5.57s\tremaining: 22.2s\n",
      "300:\ttest: 0.8227460\tbest: 0.8235735 (280)\ttotal: 8.38s\tremaining: 19.5s\n",
      "400:\ttest: 0.8245765\tbest: 0.8245765 (400)\ttotal: 11.1s\tremaining: 16.6s\n",
      "500:\ttest: 0.8241866\tbest: 0.8245846 (401)\ttotal: 13.9s\tremaining: 13.8s\n",
      "600:\ttest: 0.8245139\tbest: 0.8253808 (567)\ttotal: 16.7s\tremaining: 11.1s\n",
      "700:\ttest: 0.8266187\tbest: 0.8271406 (696)\ttotal: 19.4s\tremaining: 8.29s\n",
      "800:\ttest: 0.8261030\tbest: 0.8271406 (696)\ttotal: 22.2s\tremaining: 5.52s\n",
      "900:\ttest: 0.8272253\tbest: 0.8274233 (888)\ttotal: 25s\tremaining: 2.75s\n",
      "999:\ttest: 0.8269414\tbest: 0.8276140 (910)\ttotal: 27.8s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.8276140152\n",
      "bestIteration = 910\n",
      "\n",
      "Shrink model to first 911 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRanker at 0x114a699d0>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CatBoostRanker(\n",
    "    iterations=1000,\n",
    "    learning_rate=0.05,\n",
    "    depth=5,\n",
    "    loss_function='YetiRank',\n",
    "    eval_metric='NDCG:top=4',\n",
    "    random_seed=42,\n",
    "    verbose=100\n",
    ")\n",
    "\n",
    "model.fit(train_pool, eval_set=test_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "644aaa9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0339a59f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG Score: 0.7901939816695625\n"
     ]
    }
   ],
   "source": [
    "# You can use ranking metrics like NDCG, MAP, etc.\n",
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "# Evaluate NDCG Score\n",
    "ndcg = ndcg_score([y_test], [y_pred], k=4)\n",
    "print(f\"NDCG Score: {ndcg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7c2a605c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1080924 2100923 2110922 3080924 4080924]\n"
     ]
    }
   ],
   "source": [
    "print(groups_test.unique()[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "128d2655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted by Predicted Ranking Scores:\n",
      "    True_Rank  Predicted_Score\n",
      "7          12         3.009545\n",
      "0           3         0.915008\n",
      "1           7         0.856832\n",
      "6          11         0.846419\n",
      "9          10         0.831640\n",
      "2           6         0.525494\n",
      "11          9         0.216802\n",
      "5           2        -0.352640\n",
      "10          8        -0.535012\n",
      "3           4        -0.787465\n",
      "4           5        -0.936605\n",
      "8           1        -2.610698\n",
      "\n",
      "Sorted by True Ranking:\n",
      "    True_Rank  Predicted_Score\n",
      "8           1        -2.610698\n",
      "5           2        -0.352640\n",
      "0           3         0.915008\n",
      "3           4        -0.787465\n",
      "4           5        -0.936605\n",
      "2           6         0.525494\n",
      "1           7         0.856832\n",
      "10          8        -0.535012\n",
      "11          9         0.216802\n",
      "9          10         0.831640\n",
      "6          11         0.846419\n",
      "7          12         3.009545\n"
     ]
    }
   ],
   "source": [
    "# Choose the race you want to inspect\n",
    "specific_race = 4080924  # replace with an actual race_index value from groups_test\n",
    "\n",
    "# Filter for the specific race in test set\n",
    "race_mask = (groups_test == specific_race)\n",
    "\n",
    "# Get the horse info, true placing, predicted scores for the race\n",
    "race_true = y_test[race_mask]\n",
    "race_pred = y_pred[race_mask]\n",
    "race_data = X_test[race_mask]\n",
    "\n",
    "# Combine into a DataFrame for easy comparison\n",
    "import pandas as pd\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'True_Rank': race_true.values,\n",
    "    'Predicted_Score': race_pred\n",
    "})\n",
    "\n",
    "# Sort by predicted score (descending: highest score means better rank)\n",
    "comparison_df_sorted_by_pred = comparison_df.sort_values(by='Predicted_Score', ascending=False)\n",
    "\n",
    "# Sort by true rank (ascending: 1 is best rank)\n",
    "comparison_df_sorted_by_true = comparison_df.sort_values(by='True_Rank')\n",
    "\n",
    "print(\"Sorted by Predicted Ranking Scores:\")\n",
    "print(comparison_df_sorted_by_pred)\n",
    "\n",
    "print(\"\\nSorted by True Ranking:\")\n",
    "print(comparison_df_sorted_by_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f8640583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted by Predicted Ranking Scores (Adjusted):\n",
      "   True_Rank  Predicted_Score  Adjusted_Predicted_Score\n",
      "6          9        -1.757405                  1.757405\n",
      "7          1        -0.887398                  0.887398\n",
      "4          2        -0.828287                  0.828287\n",
      "5          3        -0.277257                  0.277257\n",
      "2          5        -0.261049                  0.261049\n",
      "0          6         0.465285                 -0.465285\n",
      "8          7         0.642855                 -0.642855\n",
      "3          4         0.727797                 -0.727797\n",
      "1          8         1.740684                 -1.740684\n",
      "\n",
      "Sorted by True Ranking:\n",
      "   True_Rank  Predicted_Score  Adjusted_Predicted_Score\n",
      "7          1        -0.887398                  0.887398\n",
      "4          2        -0.828287                  0.828287\n",
      "5          3        -0.277257                  0.277257\n",
      "3          4         0.727797                 -0.727797\n",
      "2          5        -0.261049                  0.261049\n",
      "0          6         0.465285                 -0.465285\n",
      "8          7         0.642855                 -0.642855\n",
      "1          8         1.740684                 -1.740684\n",
      "6          9        -1.757405                  1.757405\n"
     ]
    }
   ],
   "source": [
    "# Choose the race you want to inspect\n",
    "specific_race = 2100923  # replace with an actual race_index value from groups_test\n",
    "\n",
    "# Filter for the specific race in test set\n",
    "race_mask = (groups_test == specific_race)\n",
    "\n",
    "# Get the horse info, true placing, predicted scores for the race\n",
    "race_true = y_test[race_mask]\n",
    "race_pred = y_pred[race_mask]\n",
    "race_data = X_test[race_mask]\n",
    "\n",
    "# Combine into a DataFrame for easy comparison\n",
    "import pandas as pd\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'True_Rank': race_true.values,\n",
    "    'Predicted_Score': race_pred\n",
    "})\n",
    "\n",
    "# If you observe predicted scores are inversely related to true ranks, invert them for intuitive comparison\n",
    "comparison_df['Adjusted_Predicted_Score'] = -comparison_df['Predicted_Score']\n",
    "\n",
    "# Sort by predicted score (descending: highest score means better rank)\n",
    "comparison_df_sorted_by_pred = comparison_df.sort_values(by='Adjusted_Predicted_Score', ascending=False)\n",
    "\n",
    "# Sort by true rank (ascending: 1 is best rank)\n",
    "comparison_df_sorted_by_true = comparison_df.sort_values(by='True_Rank')\n",
    "\n",
    "print(\"Sorted by Predicted Ranking Scores (Adjusted):\")\n",
    "print(comparison_df_sorted_by_pred)\n",
    "\n",
    "print(\"\\nSorted by True Ranking:\")\n",
    "print(comparison_df_sorted_by_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "aae7727b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between predicted scores and true ranks: 0.565\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "correlation = np.corrcoef(y_pred, y_test)[0, 1]\n",
    "print(f\"Correlation between predicted scores and true ranks: {correlation:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b31c76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scraping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
