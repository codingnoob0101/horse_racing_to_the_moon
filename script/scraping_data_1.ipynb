{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "51b3f7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import re\n",
    "import camelot\n",
    "from datetime import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfa54a2",
   "metadata": {},
   "source": [
    "# Download pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b812f246",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = {\n",
    "    'fixture_23.pdf' : 'https://res.hkjc.com/racingnews/wp-content/uploads/sites/3/2023/07/fixture_23-24_en.pdf',\n",
    "    'fixture_24.pdf' : 'https://res.hkjc.com/racingnews/wp-content/uploads/sites/3/2024/07/fixture_24-25_e.pdf',\n",
    "    'fixture_25.pdf' : 'https://res.hkjc.com/racingnews/wp-content/uploads/sites/3/2025/07/fixture_25-26.pdf'\n",
    "}\n",
    "\n",
    "out_dir = '../data/fixtures/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6f56fc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_pdf(urls, out_dir):\n",
    "    \n",
    "    os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "    for filename, url in urls.items():\n",
    "        print(f'downloading {filename} from {url}')\n",
    "\n",
    "        try:\n",
    "            response = requests.get(url, stream = True, timeout=15)\n",
    "            if response.status_code == 200: \n",
    "                out_path = os.path.join(out_dir + filename)\n",
    "                with open(out_path, 'wb') as f:\n",
    "                    f.write(response.content)\n",
    "                print(f'file downloaded to {out_path}')\n",
    "        \n",
    "            else:\n",
    "                print(f'file download failed with url: {url}')\n",
    "        \n",
    "        except requests.RequestException as e:\n",
    "            print(f'error downloading {url}: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2f5258f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading fixture_23.pdf from https://res.hkjc.com/racingnews/wp-content/uploads/sites/3/2023/07/fixture_23-24_en.pdf\n",
      "file downloaded to ../data/fixtures/fixture_23.pdf\n",
      "downloading fixture_24.pdf from https://res.hkjc.com/racingnews/wp-content/uploads/sites/3/2024/07/fixture_24-25_e.pdf\n",
      "file downloaded to ../data/fixtures/fixture_24.pdf\n",
      "downloading fixture_25.pdf from https://res.hkjc.com/racingnews/wp-content/uploads/sites/3/2025/07/fixture_25-26.pdf\n",
      "file downloaded to ../data/fixtures/fixture_25.pdf\n"
     ]
    }
   ],
   "source": [
    "download_pdf(urls, out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14511744",
   "metadata": {},
   "source": [
    "# Clean pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4933c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables_23 = camelot.read_pdf('../data/fixtures/fixture_23.pdf', pages = 'all', flavor = 'stream')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ecdfd846",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixture_23 = tables_23[0].df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "447e6a92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Venue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DATE</td>\n",
       "      <td>DAY / TWILIGHT \\nNIGHT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sun \\n10 Sep</td>\n",
       "      <td>Sha Tin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Thu \\n4 Jul</td>\n",
       "      <td>Happy Valley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Sun \\n7 Jul</td>\n",
       "      <td>T Sha Tin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Wed \\n10 Jul</td>\n",
       "      <td>Happy Valley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Sun \\n14 Jul</td>\n",
       "      <td>T Sha Tin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date                   Venue\n",
       "0                                        \n",
       "1                                        \n",
       "2            DATE  DAY / TWILIGHT \\nNIGHT\n",
       "3            2023                        \n",
       "4    Sun \\n10 Sep                 Sha Tin\n",
       "..            ...                     ...\n",
       "97    Thu \\n4 Jul            Happy Valley\n",
       "98    Sun \\n7 Jul               T Sha Tin\n",
       "99   Wed \\n10 Jul            Happy Valley\n",
       "100  Sun \\n14 Jul               T Sha Tin\n",
       "101                                      \n",
       "\n",
       "[102 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left = fixture_23[[0, 1]].rename(columns={0: 'Date', 1: 'Venue'})\n",
    "right = fixture_23[[2, 3]].rename(columns={2: 'Date', 3: 'Venue'})\n",
    "\n",
    "df_combined = pd.concat([left, right], ignore_index=True)\n",
    "df_combined = df_combined.dropna(how='all')  # remove completely empty rows\n",
    "df_combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e6cbcba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_combined.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9336ab7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_pattern = r'(2023|2024|2025)'\n",
    "\n",
    "df_clean['year'] = None\n",
    "current_year = None\n",
    "\n",
    "for idx, val in df_clean['Date'].items():\n",
    "    if pd.notna(val) and str(val).strip().isdigit() and re.match(year_pattern, str(val).strip()):\n",
    "        current_year = str(val).strip()\n",
    "        df_clean.at[idx, 'Date'] = None\n",
    "    else:\n",
    "        df_clean.at[idx, 'year'] = current_year\n",
    "\n",
    "df_clean = df_clean.dropna(subset = ['Date']).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4ecd9fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the date format\n",
    "def format_date(date_str, year):\n",
    "    try:\n",
    "        # remove line break in 'Date'\n",
    "        date_str = date_str.replace('\\n', ' ')\n",
    "        \n",
    "        # seperate into different parts for extraction\n",
    "        parts = date_str.split()\n",
    "\n",
    "        if len(parts) >= 3:\n",
    "            day = parts[1]\n",
    "            month = parts[2]\n",
    "        else: \n",
    "            return date_str\n",
    "        \n",
    "        dt = datetime.strptime(f\"{day} {month} {year}\", \"%d %b %Y\")\n",
    "        return dt.strftime(\"%d/%m/%Y\")\n",
    "\n",
    "    except Exception:\n",
    "        return date_str\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a0dcb0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['Date'] = df_clean.apply(lambda row: format_date(row['Date'], row['year']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8ddcb982",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_clean.drop(columns=['year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "78dc8d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip leading/trailing spaces and replace pure empty strings with NaN\n",
    "df_clean = df_clean.replace(r'^\\s*$', np.nan, regex=True)\n",
    "\n",
    "# Drop rows where Date or Venue is NaN\n",
    "df_clean = df_clean.dropna(subset=['Date', 'Venue']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d11f5f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_clean[~df_clean['Date'].str.contains('DATE', case = False, na = False)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5e8a7292",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['Venue'] = df_clean['Venue'].replace(\n",
    "    {\n",
    "        r'(?i)\\bSha\\s*Tin\\b': 'ST',\n",
    "        r'(?i)\\bHappy\\s*Valley\\b': 'HV'\n",
    "    },\n",
    "    regex=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5fa48440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Venue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10/09/2023</td>\n",
       "      <td>ST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13/09/2023</td>\n",
       "      <td>HV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17/09/2023</td>\n",
       "      <td>ST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20/09/2023</td>\n",
       "      <td>HV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24/09/2023</td>\n",
       "      <td>ST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>01/07/2024</td>\n",
       "      <td>T ST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>04/07/2024</td>\n",
       "      <td>HV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>07/07/2024</td>\n",
       "      <td>T ST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>10/07/2024</td>\n",
       "      <td>HV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>14/07/2024</td>\n",
       "      <td>T ST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date Venue\n",
       "0   10/09/2023    ST\n",
       "1   13/09/2023    HV\n",
       "2   17/09/2023    ST\n",
       "3   20/09/2023    HV\n",
       "4   24/09/2023    ST\n",
       "..         ...   ...\n",
       "83  01/07/2024  T ST\n",
       "84  04/07/2024    HV\n",
       "85  07/07/2024  T ST\n",
       "86  10/07/2024    HV\n",
       "87  14/07/2024  T ST\n",
       "\n",
       "[88 rows x 2 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ee60128f",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_frame = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10407c0",
   "metadata": {},
   "source": [
    "# Function to clean fixture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbb6da5",
   "metadata": {},
   "source": [
    "## Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4444730f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the date format\n",
    "def format_date(date_str, year):\n",
    "    try:\n",
    "        # remove line break in 'Date'\n",
    "        date_str = date_str.replace('\\n', ' ')\n",
    "        \n",
    "        # seperate into different parts for extraction\n",
    "        parts = date_str.split()\n",
    "\n",
    "        if len(parts) >= 3:\n",
    "            day = parts[1]\n",
    "            month = parts[2]\n",
    "        else: \n",
    "            return date_str\n",
    "        \n",
    "        dt = datetime.strptime(f\"{day} {month} {year}\", \"%d %b %Y\")\n",
    "        return dt.strftime(\"%d/%m/%Y\")\n",
    "\n",
    "    except Exception:\n",
    "        return date_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fac74bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_fixture(fixture):\n",
    "    \n",
    "    full_frame = pd.DataFrame()\n",
    "\n",
    "    year_pattern = f'(2022|2023|2024|2025|2026)'\n",
    "\n",
    "    for f in fixture:\n",
    "        # read each pdf\n",
    "        table = camelot.read_pdf(f, pages = 'all', flavor = 'stream')\n",
    "        fixture = table[0].df\n",
    "\n",
    "        left = fixture[[0, 1]].rename(columns = {0: 'Date', 1: 'Venue'})\n",
    "        right = fixture[[2, 3]].rename(columns = {2: 'Date', 3: 'Venue'})\n",
    "\n",
    "        # concat two parts into one list\n",
    "        combined = pd.concat([left, right], ignore_index = True)\n",
    "        conbined = combined.dropna(how = 'all')\n",
    "\n",
    "        combined['year'] = None\n",
    "        current_year = None\n",
    "\n",
    "        for idx, val in combined['Date'].items():\n",
    "            if pd.notna(val) and str(val).strip().isdigit() and re.match(year_pattern, str(val).strip()):\n",
    "                current_year = str(val).strip()\n",
    "                combined.at[idx, 'Date'] = None\n",
    "            else:\n",
    "                combined.at[idx, 'year'] = current_year\n",
    "\n",
    "        combined = combined.dropna(subset = ['Date']).reset_index(drop = True)\n",
    "\n",
    "        combined['Date'] = combined.apply(lambda row: format_date(row['Date'], row['year']), axis = 1)\n",
    "        combined = combined.drop(columns = ['year'])\n",
    "\n",
    "        combined = combined.replace(r'^\\s*$', np.nan, regex=True)      \n",
    "        combined = combined.dropna(subset=['Date', 'Venue']).reset_index(drop=True)  \n",
    "\n",
    "        combined = combined[~combined['Date'].str.contains('DATE', case = False, na = False)].reset_index(drop=True)\n",
    "        combined['Venue'] = combined['Venue'].replace(\n",
    "            {\n",
    "                r'(?i)\\bSha\\s*Tin\\b': 'ST',\n",
    "                r'(?i)\\bHappy\\s*Valley\\b': 'HV'\n",
    "            },\n",
    "            regex=True\n",
    "        )\n",
    "\n",
    "        full_frame = pd.concat([full_frame,combined], ignore_index = True)\n",
    "\n",
    "    return full_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "df159ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_list = [\n",
    "    \"../data/fixtures/fixture_23.pdf\",\n",
    "    \"../data/fixtures/fixture_24.pdf\",\n",
    "    \"../data/fixtures/fixture_25.pdf\"\n",
    "]\n",
    "\n",
    "df = clean_fixture(pdf_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5844fd7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Date Venue\n",
      "0                 10/09/2023    ST\n",
      "1                 13/09/2023    HV\n",
      "2                 17/09/2023    ST\n",
      "3                 20/09/2023    HV\n",
      "4                 24/09/2023    ST\n",
      "..                       ...   ...\n",
      "130  Sha Tin (LONGINES HKIR)   Sun\n",
      "131             Happy Valley   Wed\n",
      "132                  Sha Tin   Sun\n",
      "133             Happy Valley   Wed\n",
      "134                  Sha Tin   Sun\n",
      "\n",
      "[135 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7c304e",
   "metadata": {},
   "source": [
    "# scrape by date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a51d02a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = ['2025/07/16']\n",
    "venue = ['HV', 'ST']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ddd5faba",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'dates': date,\n",
    "    'venues': venue\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677fa2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_race_data_by_venue(date, venues, max_race_no=9):\n",
    " \n",
    "    base_url = \"https://racing.hkjc.com/racing/information/English/Racing/LocalResults.aspx\"\n",
    "    results = {}\n",
    "\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (compatible; HKJCScraper/1.0)\"\n",
    "    }\n",
    "\n",
    "    for venue in venues:\n",
    "        print(f\"Checking venue {venue} race no 1...\")\n",
    "        params = {\n",
    "            \"RaceDate\": date,\n",
    "            \"Racecourse\": venue,\n",
    "            \"RaceNo\": 1\n",
    "        }\n",
    "\n",
    "        response = requests.get(base_url, params=params, headers=headers)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Failed to fetch page for venue {venue} race 1, status: {response.status_code}\")\n",
    "            continue\n",
    "\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        # Check for the presence of the race result table, often with class 'table_bd' or id\n",
    "        table = soup.find('table', class_='table_bd')\n",
    "\n",
    "        if not table:\n",
    "            print(f\"No race data found for venue {venue} race 1; skipping rest of races for this venue.\")\n",
    "            continue  # Skip race 2-9 for this venue\n",
    "\n",
    "        # Save race 1 result\n",
    "        results[(venue, 1)] = soup\n",
    "        print(f\"Race data found for venue {venue} race 1; fetching races 2 to {max_race_no}...\")\n",
    "\n",
    "        # Now fetch the rest of the races for this venue\n",
    "        for race_no in range(2, max_race_no + 1):\n",
    "            params[\"RaceNo\"] = race_no\n",
    "            response = requests.get(base_url, params=params, headers=headers)\n",
    "            if response.status_code != 200:\n",
    "                print(f\"Failed to fetch page for venue {venue} race {race_no}, status: {response.status_code}\")\n",
    "                results[(venue, race_no)] = None\n",
    "                continue\n",
    "\n",
    "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "            table = soup.find('table', class_='table_bd')\n",
    "            if not table:\n",
    "                print(f\"No race data found for venue {venue} race {race_no}.\")\n",
    "                results[(venue, race_no)] = None\n",
    "            else:\n",
    "                results[(venue, race_no)] = soup\n",
    "\n",
    "    return results\n",
    "\n",
    "# Example of calling the function\n",
    "if __name__ == \"__main__\":\n",
    "    race_date = '2025/07/16'\n",
    "    venue_list = ['HV', 'ST']\n",
    "\n",
    "    data = fetch_race_data_by_venue(race_date, venue_list)\n",
    "    # 'data' contains BeautifulSoup objects for successful pages or None entries for misses\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scraping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
