{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b54ebec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install selenium requests pandas beautifulsoup4 webdriver-manager python-dateutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c6c7740",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d8d384",
   "metadata": {},
   "source": [
    "# Configuration and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b161ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded. Output directory: data_container/\n"
     ]
    }
   ],
   "source": [
    "# configuration and setup \n",
    "class Config:\n",
    "    \n",
    "    # Scraping settings\n",
    "    RATE_LIMIT = 2  # seconds between requests\n",
    "    BATCH_SIZE = 10  # races per batch\n",
    "    \n",
    "    # Selenium settings\n",
    "    HEADLESS = True  # Set to False to see browser window\n",
    "    IMPLICIT_WAIT = 10\n",
    "    PAGE_LOAD_TIMEOUT = 30\n",
    "    \n",
    "    # File output settings\n",
    "    OUTPUT_DIR = \"data_container/\"\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(Config.OUTPUT_DIR, exist_ok=True)  # exist_ok make sure not to double the creation of the directory if it already exist \n",
    "print(f\"Configuration loaded. Output directory: {Config.OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "158d0966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup webdriver\n",
    "def setup_webdriver():\n",
    "    chrome_options = Options()\n",
    "    \n",
    "    if Config.HEADLESS: # HEADLESS = True from config\n",
    "        chrome_options.add_argument('--headless')\n",
    "    \n",
    "    # Performance options\n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    chrome_options.add_argument(\"--disable-gpu\")\n",
    "    chrome_options.add_argument(\"--window-size=1920,1080\")\n",
    "    chrome_options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    chrome_options.add_experimental_option('useAutomationExtension', False)\n",
    "\n",
    "    # User agent -- pretend to be regular user browser to prevent block/detection\n",
    "    chrome_options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')\n",
    "\n",
    "    # Setup driver\n",
    "    service = Service(ChromeDriverManager().install()) # install the correct chromedriver for browser\n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options) \n",
    "\n",
    "    # Config timeouts\n",
    "    driver.implicitly_wait(Config.IMPLICIT_WAIT) # set wait time for the content to load\n",
    "    driver.set_page_load_timeout(Config.PAGE_LOAD_TIMEOUT) # maximum time allow the page to load\n",
    "\n",
    "    # Hide webdriver property -- hind automation signature to avoid bot detection\n",
    "    driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
    "\n",
    "    return driver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ccdba16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing WebDriver setup...\n",
      "WebDriver setup successful! Browser: chrome 138.0.7204.184\n",
      "WebDriver test completed.\n"
     ]
    }
   ],
   "source": [
    "# Test WebDriver setup\n",
    "print(\"Testing WebDriver setup...\")\n",
    "\n",
    "try:\n",
    "    test_driver = setup_webdriver()\n",
    "    print(f\"WebDriver setup successful! Browser: {test_driver.capabilities['browserName']} {test_driver.capabilities['browserVersion']}\")\n",
    "    test_driver.quit()\n",
    "    print(\"WebDriver test completed.\")\n",
    "\n",
    "# python creates a Exception object whenever it encounters an error\n",
    "except Exception as e: \n",
    "    print(f\"WebDriver setup failed: {e}\")\n",
    "    print(\"Make sure Chrome browser is installed on your system.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66b7e625",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = '2025/07/16'\n",
    "venue = 'HV'\n",
    "race_no = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31ee2b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = setup_webdriver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4fb36d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f'https://racing.hkjc.com/racing/information/English/Racing/LocalResults.aspx?RaceDate={date}&Racecourse={venue}&RaceNo={race_no}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6eaaa65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76cc4c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2387e95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_table = soup.find('div', class_ = 'race_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1335facf",
   "metadata": {},
   "outputs": [],
   "source": [
    "race_info ={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e4f6138",
   "metadata": {},
   "outputs": [],
   "source": [
    "race_info['date'] = date\n",
    "race_info['venue'] = venue\n",
    "race_info['race_no'] = race_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "71a2aedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_class(soup):\n",
    "    # find class label in soup\n",
    "    try:\n",
    "        race_class = soup.find_all(['td'], string = lambda text: text and ('Class' in text))\n",
    "\n",
    "        for c in race_class:\n",
    "            response = c.get_text()\n",
    "            if 'Class' in response:\n",
    "                classes = re.search(r\"^(Class [1-5])\", response)\n",
    "                race_info['race_class'] = classes.group(0)\n",
    "                print(classes.group(0))\n",
    "                \n",
    "                length = re.search(r\"\\b(\\d{3,4})M\\b\", response)\n",
    "                race_info['length'] = length.group(0)\n",
    "                print(length.group(0))\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# Find the condition of the course\n",
    "def find_going(soup): \n",
    "    try:\n",
    "        going = soup.find_all(['td'], string = lambda text : text and ('GOOD TO FIRM' in text))\n",
    "\n",
    "        for t in going:\n",
    "            response = t.get_text()\n",
    "            race_info['course condition'] = response\n",
    "            print(f'Course condition: {response}')\n",
    "\n",
    "    except:\n",
    "        pass    \n",
    "\n",
    "def find_course(soup):\n",
    "    try:\n",
    "        course_label = soup.find(['td'], string = lambda text : text and 'Course' in text)\n",
    "        if course_label:\n",
    "            course_info = course_label.find_next().get_text(strip = True)\n",
    "            race_info['course'] = course_info\n",
    "            print(f'course info: {course_info}')\n",
    "\n",
    "    except:\n",
    "        pass    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d2ceb17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_result(soup):\n",
    "    try:\n",
    "        table = soup.find('table', class_ = 'f_tac table_bd draggable')\n",
    "        headers = [td.get_text(strip=True) for td in table.find('thead').find_all('td')]\n",
    "\n",
    "        data_rows = []\n",
    "    \n",
    "        for row in table.find('tbody').find_all('tr'):\n",
    "           cols = [td.get_text(strip=True) for td in row.find_all('td')]\n",
    "           if cols and any(cols):   # skip empty rows\n",
    "               data_rows.append(cols)\n",
    "    \n",
    "        table_data = [dict(zip(headers, row)) for row in data_rows]\n",
    "        print(table_data)\n",
    "\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f0b3347e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Course condition: GOOD TO FIRM\n",
      "Class 5\n",
      "1200M\n",
      "course info: TURF - \"B\" Course\n",
      "[{'Pla.': '1', 'Horse No.': '11', 'Horse': 'SPEEDY SMARTIE(H108)', 'Jockey': 'L Ferraris', 'Trainer': 'T P Yung', 'Act. Wt.': '123', 'Declar. Horse Wt.': '1125', 'Dr.': '7', 'LBW': '-', 'RunningPosition': '111', 'Finish Time': '1:09.96', 'Win Odds': '7.7'}, {'Pla.': '2', 'Horse No.': '5', 'Horse': 'RAGNARR(H297)', 'Jockey': 'M F Poon', 'Trainer': 'D J Hall', 'Act. Wt.': '130', 'Declar. Horse Wt.': '1049', 'Dr.': '4', 'LBW': 'NOSE', 'RunningPosition': '432', 'Finish Time': '1:09.97', 'Win Odds': '6.2'}, {'Pla.': '3', 'Horse No.': '4', 'Horse': 'DAN ATTACK(H317)', 'Jockey': 'H Bowman', 'Trainer': 'D J Whyte', 'Act. Wt.': '131', 'Declar. Horse Wt.': '1206', 'Dr.': '2', 'LBW': 'HD', 'RunningPosition': '223', 'Finish Time': '1:10.00', 'Win Odds': '5.5'}, {'Pla.': '4', 'Horse No.': '9', 'Horse': \"YOU'REMYEVERYTHING(E413)\", 'Jockey': 'K C Leung', 'Trainer': 'C W Chang', 'Act. Wt.': '126', 'Declar. Horse Wt.': '996', 'Dr.': '5', 'LBW': '1/2', 'RunningPosition': '764', 'Finish Time': '1:10.07', 'Win Odds': '6.1'}, {'Pla.': '5', 'Horse No.': '10', 'Horse': 'EVER SMART(J179)', 'Jockey': 'C L Chau', 'Trainer': 'F C Lor', 'Act. Wt.': '122', 'Declar. Horse Wt.': '1144', 'Dr.': '11', 'LBW': '2-3/4', 'RunningPosition': '885', 'Finish Time': '1:10.42', 'Win Odds': '21'}, {'Pla.': '6', 'Horse No.': '8', 'Horse': 'TALENTS SUPREMO(H133)', 'Jockey': 'K Teetan', 'Trainer': 'W K Mo', 'Act. Wt.': '128', 'Declar. Horse Wt.': '1101', 'Dr.': '9', 'LBW': '3-1/4', 'RunningPosition': '996', 'Finish Time': '1:10.49', 'Win Odds': '36'}, {'Pla.': '7', 'Horse No.': '1', 'Horse': 'TRIUMPHANT WARRIOR(H430)', 'Jockey': 'Z Purton', 'Trainer': 'C S Shum', 'Act. Wt.': '135', 'Declar. Horse Wt.': '1075', 'Dr.': '3', 'LBW': '4', 'RunningPosition': '347', 'Finish Time': '1:10.60', 'Win Odds': '3.4'}, {'Pla.': '8', 'Horse No.': '3', 'Horse': 'WINNING HEART(H065)', 'Jockey': 'M Chadwick', 'Trainer': 'A S Cruz', 'Act. Wt.': '133', 'Declar. Horse Wt.': '1155', 'Dr.': '1', 'LBW': '5', 'RunningPosition': '11118', 'Finish Time': '1:10.76', 'Win Odds': '10'}, {'Pla.': '9', 'Horse No.': '12', 'Horse': 'SUPERB MOVE(G304)', 'Jockey': 'Y L Chung', 'Trainer': 'C H Yip', 'Act. Wt.': '113', 'Declar. Horse Wt.': '1133', 'Dr.': '8', 'LBW': '5-1/2', 'RunningPosition': '559', 'Finish Time': '1:10.86', 'Win Odds': '54'}, {'Pla.': '10', 'Horse No.': '6', 'Horse': 'SPORTIC WARRIOR(J385)', 'Jockey': 'B Thompson', 'Trainer': 'K L Man', 'Act. Wt.': '130', 'Declar. Horse Wt.': '1074', 'Dr.': '10', 'LBW': '9', 'RunningPosition': '101010', 'Finish Time': '1:11.40', 'Win Odds': '165'}, {'Pla.': '11', 'Horse No.': '7', 'Horse': 'MACANESE MASTER(J532)', 'Jockey': 'J Orman', 'Trainer': 'Y S Tsui', 'Act. Wt.': '129', 'Declar. Horse Wt.': '1073', 'Dr.': '12', 'LBW': '10-1/4', 'RunningPosition': '121211', 'Finish Time': '1:11.60', 'Win Odds': '98'}, {'Pla.': '12', 'Horse No.': '2', 'Horse': 'MY INTELLIGENT(G031)', 'Jockey': 'E C W Wong', 'Trainer': 'W Y So', 'Act. Wt.': '128', 'Declar. Horse Wt.': '1125', 'Dr.': '6', 'LBW': '10-1/4', 'RunningPosition': '6712', 'Finish Time': '1:11.60', 'Win Odds': '13'}]\n"
     ]
    }
   ],
   "source": [
    "find_going(soup)\n",
    "find_class(soup)\n",
    "find_course(soup)\n",
    "find_result(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c7bc04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9fe7e6d",
   "metadata": {},
   "source": [
    "# Define scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6b80306a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ HKJCScraper class ready!\n"
     ]
    }
   ],
   "source": [
    "# Main HKJC Scraper Class\n",
    "class HKJCScraper:\n",
    "    def __init__(self): # when starting a new scraper instance\n",
    "        self.driver = None \n",
    "        self.all_data = [] # start a empty list to collect data\n",
    "        self.processed_count = 0 # counting how many race pages have been processed\n",
    "        self.errors = [] # start a empty list to log errors for debugging\n",
    "\n",
    "\n",
    "    # browser management\n",
    "    def start_browser(self):\n",
    "        \"\"\"Start the browser\"\"\"\n",
    "        if self.driver is None: # check if browser is already running\n",
    "            self.driver = setup_webdriver() # setup the webdriver by using function defined above\n",
    "            print(\"Browser started\")\n",
    "    \n",
    "    def stop_browser(self):\n",
    "        \"\"\"Stop the browser\"\"\"\n",
    "        if self.driver: # is not none means browser is running\n",
    "            self.driver.quit() # close the browser\n",
    "            self.driver = None # reset the driver to None\n",
    "            print(\"Browser stopped\")\n",
    "\n",
    "\n",
    "    # define main scraper\n",
    "    def scrape_single_race(self, date, venue, race_no):\n",
    "        try:\n",
    "            # build the url from info provided\n",
    "            date_str = date.strftime('%Y/%m/%d')\n",
    "            url = f'https://racing.hkjc.com/racing/information/English/Racing/LocalResults.aspx?RaceDate={date_str}&Racecourse={venue}&RaceNo={race_no}'\n",
    "\n",
    "            print(f'scraping: {date.strftime(\"%Y-%m-%d\")}, {venue}, Race:{race_no}')\n",
    "\n",
    "            # get page content\n",
    "            self.driver.get(url)\n",
    "            time.sleep(2) # wait for the page to load\n",
    "            soup = BeautifulSoup(self.driver.page_source, 'html.parser')\n",
    "\n",
    "            # check if race exists (look for results table)\n",
    "            results_table = soup.find('table', class_='table_bd')\n",
    "            if not results_table:\n",
    "                print(f\"No results found for {date.strftime('%Y-%m-%d')}\")\n",
    "                return False\n",
    "\n",
    "            # Extract basic race info\n",
    "            race_info = {\n",
    "                'date': date.strftime('%Y-%m-%d'),\n",
    "                'venue': venue,\n",
    "                'race_no': race_no,\n",
    "                'data_type': 'race_info',\n",
    "                'scrape_time': datetime.now().isoformat()\n",
    "            }\n",
    "\n",
    "            # Try to extract race details by finding 'Class', 'HANDICAP', or 'M' in text\n",
    "            try:\n",
    "                # Find all relevant divs, spans, or table with filters with lambda function, selecting those only with 'Class', 'HANDICAP', or 'M' in text\n",
    "                race_detail_divs = soup.find_all(['div', 'span', 'td'], string = lambda text: text and ('Class' in text or 'HANDICAP' in text or 'M' in text))\n",
    "                for div in race_detail_divs[:3]: # check the first 3 elements because they often appears at the top of the page\n",
    "                    text = div.get_text() \n",
    "                    if 'Class' in text: # check if 'Class' is in the text\n",
    "                        race_info['race_class'] = text.strip()\n",
    "                    if any(char.isdigit() and 'M' in text for char in text): # quick check if there is a digit followed by 'M' in the text\n",
    "                        import re\n",
    "                        distance_match = re.search(r'(\\d+)M', text) # extract the distance in meters using regex\n",
    "                        if distance_match:\n",
    "                            race_info['distance'] = distance_match.group(0) # .group(0): return the whole regex match. .group(1): return the first capturing group\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            # Extract the horse performance\n",
    "            performances = [] # initialize a list to store performances\n",
    "            try:\n",
    "                rows = results_table.find_all('tr')[1:]  # skip header row\n",
    "            \n",
    "                for row in rows:\n",
    "                    cells = row.find_all(['td', 'th'])\n",
    "                    if len(cells) >= 6: # exclude if shorter than 6 columns\n",
    "\n",
    "                        # Extract horse ID from link if available\n",
    "                        horse_id = None\n",
    "                        horse_name = cells[2].get_text(strip=True) if len(cells) > 2 else ''\n",
    "                        horse_link = cells[2].find('a') if len(cells) > 2 else None\n",
    "                        if horse_link and horse_link.get('href'):\n",
    "                            import re\n",
    "                            match = re.search(r'HorseId=([^&]+)', horse_link['href'])\n",
    "                            if match:\n",
    "                                horse_id = match.group(1)\n",
    "                        \n",
    "                        performance = {\n",
    "                            'date': date.strftime('%Y-%m-%d'),\n",
    "                            'venue': venue,\n",
    "                            'race_no': race_no,\n",
    "                            'data_type': 'performance',\n",
    "                            'position': cells[0].get_text(strip=True),\n",
    "                            'horse_no': cells[1].get_text(strip=True) if len(cells) > 1 else '',\n",
    "                            'horse_name': horse_name,\n",
    "                            'horse_id': horse_id,\n",
    "                            'jockey': cells[3].get_text(strip=True) if len(cells) > 3 else '',\n",
    "                            'trainer': cells[4].get_text(strip=True) if len(cells) > 4 else '',\n",
    "                            'weight': cells[5].get_text(strip=True) if len(cells) > 5 else '',\n",
    "                            'draw': cells[6].get_text(strip=True) if len(cells) > 6 else '',\n",
    "                            'margin': cells[7].get_text(strip=True) if len(cells) > 7 else '',\n",
    "                            'time': cells[8].get_text(strip=True) if len(cells) > 8 else '',\n",
    "                            'odds': cells[9].get_text(strip=True) if len(cells) > 9 else '',\n",
    "                            'scrape_time': datetime.now().isoformat()\n",
    "                        }\n",
    "                        performances.append(performance)\n",
    "            except Exception as e:\n",
    "                print(f'error extracting performances: {e}')\n",
    "            \n",
    "\n",
    "            self.all_data.append(race_info)\n",
    "            self.all_data.extend(performance)\n",
    "\n",
    "            self.processed_count += 1\n",
    "            print(f\"Extracted {len(performances)} horses\")\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = f\"Error scraping {date.strftime('%Y-%m-%d')} {venue} R{race_no}: {str(e)}\"\n",
    "            print(f\" {error_msg}\")\n",
    "            self.errors.append(error_msg)\n",
    "            return False\n",
    "    \n",
    "    def save_data(self, filename_prefix=\"hkjc_data\"):\n",
    "        \"\"\"Save all collected data to CSV\"\"\"\n",
    "        if not self.all_data:\n",
    "            print(\"No data to save!\")\n",
    "            return\n",
    "        \n",
    "        # Convert to DataFrame from dictonaries\n",
    "        df = pd.DataFrame(self.all_data)\n",
    "        \n",
    "        # Save main data file\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        filename = f\"{Config.OUTPUT_DIR}{filename_prefix}_{timestamp}.csv\"\n",
    "        df.to_csv(filename, index=False)\n",
    "        print(f\"✅ Saved {len(df)} records to {filename}\")\n",
    "        \n",
    "        # Save separate files by data type\n",
    "        for data_type in df['data_type'].unique():\n",
    "            type_df = df[df['data_type'] == data_type]\n",
    "            type_filename = f\"{Config.OUTPUT_DIR}{filename_prefix}_{data_type}_{timestamp}.csv\"\n",
    "            type_df.to_csv(type_filename, index=False)\n",
    "            print(f\"  📊 {data_type}: {len(type_df)} records → {type_filename}\")\n",
    "        \n",
    "        # Save errors if any\n",
    "        if self.errors:\n",
    "            error_filename = f\"{Config.OUTPUT_DIR}{filename_prefix}_errors_{timestamp}.txt\"\n",
    "            with open(error_filename, 'w') as f:\n",
    "                for error in self.errors:\n",
    "                    f.write(error + '\\\\n')\n",
    "            print(f\"  ⚠️ Saved {len(self.errors)} errors to {error_filename}\")\n",
    "        \n",
    "        return filename\n",
    "\n",
    "print(\"✅ HKJCScraper class ready!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8f142116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Testing utility functions...\n",
      "✅ Generated 13 race dates for January 2024\n",
      "📅 Sample dates: ['2024-01-03 Wednesday', '2024-01-06 Saturday', '2024-01-07 Sunday']\n",
      "🏟️ Venues: ['ST', 'HV']\n",
      "🏇 Race numbers: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "✅ All utility functions ready!\n"
     ]
    }
   ],
   "source": [
    "# Utility Functions\n",
    "def generate_race_dates(start_date, end_date):\n",
    "    \"\"\"Generate list of race dates (typically Wed, Sat, Sun)\"\"\"\n",
    "    start = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "    end = datetime.strptime(end_date, '%Y-%m-%d')\n",
    "    \n",
    "    race_dates = []\n",
    "    current = start\n",
    "    \n",
    "    while current <= end:\n",
    "        # Check if it's a racing day (Wednesday=2, Saturday=5, Sunday=6)\n",
    "        if current.weekday() in [2, 5, 6]:\n",
    "            race_dates.append(current)\n",
    "        current += timedelta(days=1)\n",
    "    \n",
    "    return race_dates\n",
    "\n",
    "def get_race_venues():\n",
    "    \"\"\"Get list of race venues\"\"\"\n",
    "    return ['ST', 'HV']  # Sha Tin, Happy Valley\n",
    "\n",
    "def get_race_numbers():\n",
    "    \"\"\"Get typical race numbers\"\"\"\n",
    "    return list(range(1, 12))  # Races 1-11\n",
    "\n",
    "# Main scraping function\n",
    "def run_hkjc_scraper(start_date=None, end_date=None, venues=None, max_races=None):\n",
    "    \"\"\"Run the HKJC scraper\"\"\"\n",
    "    \n",
    "    # Set defaults\n",
    "    # if start_date is None:\n",
    "    #     start_date = \"2024-01-01\"\n",
    "    # if end_date is None:\n",
    "    #     end_date = \"2024-01-31\"\n",
    "    # if venues is None:\n",
    "    #     venues = ['ST']  # Default to Sha Tin only\n",
    "    \n",
    "    print(f\"🚀 Starting HKJC scraper\")\n",
    "    print(f\"📅 Date range: {start_date} to {end_date}\")\n",
    "    print(f\"🏟️ Venues: {venues}\")\n",
    "    print(f\"🎯 Max races: {max_races if max_races else 'No limit'}\")\n",
    "    \n",
    "    # Initialize scraper\n",
    "    scraper = HKJCScraper()\n",
    "    \n",
    "    try:\n",
    "        # Start browser\n",
    "        scraper.start_browser()\n",
    "        \n",
    "        # Generate race dates\n",
    "        race_dates = generate_race_dates(start_date, end_date)\n",
    "        print(f\"📊 Found {len(race_dates)} potential race dates\")\n",
    "        \n",
    "        total_processed = 0\n",
    "        \n",
    "        # Process each date\n",
    "        for race_date in race_dates:\n",
    "            if max_races and total_processed >= max_races:\n",
    "                print(f\"🛑 Reached maximum races limit ({max_races})\")\n",
    "                break\n",
    "                \n",
    "            print(f\"\\\\n📅 Processing {race_date.strftime('%Y-%m-%d %A')}\")\n",
    "            \n",
    "            # Process each venue\n",
    "            for venue in venues:\n",
    "                if max_races and total_processed >= max_races:\n",
    "                    break\n",
    "                    \n",
    "                print(f\"  🏟️ Venue: {venue}\")\n",
    "                \n",
    "                # Process races 1-11\n",
    "                for race_no in get_race_numbers():\n",
    "                    if max_races and total_processed >= max_races:\n",
    "                        break\n",
    "                    \n",
    "                    success = scraper.scrape_single_race(race_date, venue, race_no)\n",
    "                    \n",
    "                    if success:\n",
    "                        total_processed += 1\n",
    "                        print(f\"    📈 Progress: {total_processed}/{max_races if max_races else '∞'}\")\n",
    "                    \n",
    "                    # Rate limiting\n",
    "                    time.sleep(Config.RATE_LIMIT)\n",
    "                    \n",
    "                    # Save data periodically\n",
    "                    if total_processed % Config.BATCH_SIZE == 0 and total_processed > 0:\n",
    "                        print(f\"\\\\n💾 Saving batch at {total_processed} races...\")\n",
    "                        scraper.save_data(f\"batch_{total_processed//Config.BATCH_SIZE:03d}\")\n",
    "        \n",
    "        # Final save\n",
    "        print(f\"\\\\n💾 Final save...\")\n",
    "        final_file = scraper.save_data(\"final\")\n",
    "        \n",
    "        # Summary\n",
    "        print(f\"\\\\n📊 === SCRAPING SUMMARY ===\")\n",
    "        print(f\"✅ Total races processed: {scraper.processed_count}\")\n",
    "        print(f\"📁 Total data records: {len(scraper.all_data)}\")\n",
    "        print(f\"❌ Errors encountered: {len(scraper.errors)}\")\n",
    "        print(f\"💾 Final data file: {final_file}\")\n",
    "        \n",
    "        return scraper\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"💥 Fatal error: {e}\")\n",
    "        return None\n",
    "        \n",
    "    finally:\n",
    "        # Always clean up\n",
    "        scraper.stop_browser()\n",
    "        print(\"🧹 Cleanup completed\")\n",
    "\n",
    "# Test the utility functions\n",
    "print(\"🔧 Testing utility functions...\")\n",
    "test_dates = generate_race_dates('2024-01-01', '2024-01-31')\n",
    "print(f\"✅ Generated {len(test_dates)} race dates for January 2024\")\n",
    "print(f\"📅 Sample dates: {[d.strftime('%Y-%m-%d %A') for d in test_dates[:3]]}\")\n",
    "print(f\"🏟️ Venues: {get_race_venues()}\")\n",
    "print(f\"🏇 Race numbers: {get_race_numbers()}\")\n",
    "print(\"✅ All utility functions ready!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "529852a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 === TEST RUN ===\n",
      "Running test with small sample to verify everything works...\n",
      "🚀 Starting HKJC scraper\n",
      "📅 Date range: 2024-01-03 to 2024-01-07\n",
      "🏟️ Venues: ['ST']\n",
      "🎯 Max races: 3\n",
      "Browser started\n",
      "📊 Found 3 potential race dates\n",
      "\\n📅 Processing 2024-01-03 Wednesday\n",
      "  🏟️ Venue: ST\n",
      "scraping: 2024-01-03, ST, Race:1\n",
      "No results found for 2024-01-03\n",
      "scraping: 2024-01-03, ST, Race:2\n",
      "No results found for 2024-01-03\n",
      "scraping: 2024-01-03, ST, Race:3\n",
      "Browser stopped\n",
      "🧹 Cleanup completed\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[70]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mRunning test with small sample to verify everything works...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Test with just a few races from January 2024\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m test_result = \u001b[43mrun_hkjc_scraper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstart_date\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m2024-01-03\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# A Wednesday  \u001b[39;49;00m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mend_date\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m2024-01-07\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# A Sunday\u001b[39;49;00m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvenues\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mST\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# Just Sha Tin\u001b[39;49;00m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_races\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m              \u001b[49m\u001b[38;5;66;43;03m# Only 3 races total\u001b[39;49;00m\n\u001b[32m     11\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mn🧪 === TEST COMPLETED ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m test_result:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[69]\u001b[39m\u001b[32m, line 76\u001b[39m, in \u001b[36mrun_hkjc_scraper\u001b[39m\u001b[34m(start_date, end_date, venues, max_races)\u001b[39m\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m max_races \u001b[38;5;129;01mand\u001b[39;00m total_processed >= max_races:\n\u001b[32m     74\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m success = \u001b[43mscraper\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscrape_single_race\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrace_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvenue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrace_no\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[32m     79\u001b[39m     total_processed += \u001b[32m1\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[68]\u001b[39m\u001b[32m, line 36\u001b[39m, in \u001b[36mHKJCScraper.scrape_single_race\u001b[39m\u001b[34m(self, date, venue, race_no)\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# get page content\u001b[39;00m\n\u001b[32m     35\u001b[39m \u001b[38;5;28mself\u001b[39m.driver.get(url)\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# wait for the page to load\u001b[39;00m\n\u001b[32m     37\u001b[39m soup = BeautifulSoup(\u001b[38;5;28mself\u001b[39m.driver.page_source, \u001b[33m'\u001b[39m\u001b[33mhtml.parser\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# check if race exists (look for results table)\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# 🧪 TEST RUN - Small sample\n",
    "print(\"🧪 === TEST RUN ===\")\n",
    "print(\"Running test with small sample to verify everything works...\")\n",
    "\n",
    "# Test with just a few races from January 2024\n",
    "test_result = run_hkjc_scraper(\n",
    "    start_date='2024-01-03',  # A Wednesday  \n",
    "    end_date='2024-01-07',    # A Sunday\n",
    "    venues=['ST'],            # Just Sha Tin\n",
    "    max_races=3              # Only 3 races total\n",
    ")\n",
    "\n",
    "print(\"\\\\n🧪 === TEST COMPLETED ===\")\n",
    "if test_result:\n",
    "    print(\"✅ Test successful! The scraper is working correctly.\")\n",
    "    print(\"💡 You can now run larger scraping jobs.\")\n",
    "else:\n",
    "    print(\"❌ Test failed. Check the error messages above.\")\n",
    "    print(\"💡 Make sure Chrome browser is installed and internet connection is stable.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ea65ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scraping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
