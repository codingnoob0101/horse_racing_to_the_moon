{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b54ebec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\tcl0011\\appdata\\local\\anaconda3\\envs\\ml1\\lib\\site-packages (4.34.2)\n",
      "Requirement already satisfied: requests in c:\\users\\tcl0011\\appdata\\local\\anaconda3\\envs\\ml1\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\tcl0011\\appdata\\local\\anaconda3\\envs\\ml1\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\tcl0011\\appdata\\local\\anaconda3\\envs\\ml1\\lib\\site-packages (4.13.4)\n",
      "Collecting webdriver-manager\n",
      "  Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\tcl0011\\appdata\\local\\anaconda3\\envs\\ml1\\lib\\site-packages (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3~=2.5.0 in c:\\users\\tcl0011\\appdata\\local\\anaconda3\\envs\\ml1\\lib\\site-packages (from urllib3[socks]~=2.5.0->selenium) (2.5.0)\n",
      "Requirement already satisfied: trio~=0.30.0 in c:\\users\\tcl0011\\appdata\\local\\anaconda3\\envs\\ml1\\lib\\site-packages (from selenium) (0.30.0)\n",
      "Requirement already satisfied: trio-websocket~=0.12.2 in c:\\users\\tcl0011\\appdata\\local\\anaconda3\\envs\\ml1\\lib\\site-packages (from selenium) (0.12.2)\n",
      "Requirement already satisfied: certifi>=2025.6.15 in c:\\users\\tcl0011\\appdata\\local\\anaconda3\\envs\\ml1\\lib\\site-packages (from selenium) (2025.7.9)\n",
      "Requirement already satisfied: typing_extensions~=4.14.0 in c:\\users\\tcl0011\\appdata\\local\\anaconda3\\envs\\ml1\\lib\\site-packages (from selenium) (4.14.1)\n",
      "Requirement already satisfied: websocket-client~=1.8.0 in c:\\users\\tcl0011\\appdata\\local\\anaconda3\\envs\\ml1\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\tcl0011\\appdata\\local\\anaconda3\\envs\\ml1\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tcl0011\\appdata\\local\\anaconda3\\envs\\ml1\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\tcl0011\\appdata\\local\\anaconda3\\envs\\ml1\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\tcl0011\\appdata\\local\\anaconda3\\envs\\ml1\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\tcl0011\\appdata\\local\\anaconda3\\envs\\ml1\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\tcl0011\\appdata\\local\\anaconda3\\envs\\ml1\\lib\\site-packages (from beautifulsoup4) (2.7)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\tcl0011\\appdata\\local\\anaconda3\\envs\\ml1\\lib\\site-packages (from webdriver-manager) (1.1.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\tcl0011\\appdata\\local\\anaconda3\\envs\\ml1\\lib\\site-packages (from webdriver-manager) (24.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\tcl0011\\appdata\\local\\anaconda3\\envs\\ml1\\lib\\site-packages (from python-dateutil) (1.16.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\tcl0011\\appdata\\local\\anaconda3\\envs\\ml1\\lib\\site-packages (from trio~=0.30.0->selenium) (25.3.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\tcl0011\\appdata\\local\\anaconda3\\envs\\ml1\\lib\\site-packages (from trio~=0.30.0->selenium) (2.4.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\tcl0011\\appdata\\local\\anaconda3\\envs\\ml1\\lib\\site-packages (from trio~=0.30.0->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\tcl0011\\appdata\\local\\anaconda3\\envs\\ml1\\lib\\site-packages (from trio~=0.30.0->selenium) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\tcl0011\\appdata\\local\\anaconda3\\envs\\ml1\\lib\\site-packages (from trio~=0.30.0->selenium) (1.17.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\tcl0011\\appdata\\local\\anaconda3\\envs\\ml1\\lib\\site-packages (from trio-websocket~=0.12.2->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\tcl0011\\appdata\\local\\anaconda3\\envs\\ml1\\lib\\site-packages (from urllib3[socks]~=2.5.0->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\tcl0011\\appdata\\local\\anaconda3\\envs\\ml1\\lib\\site-packages (from cffi>=1.14->trio~=0.30.0->selenium) (2.22)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\tcl0011\\appdata\\local\\anaconda3\\envs\\ml1\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.12.2->selenium) (0.16.0)\n",
      "Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl (27 kB)\n",
      "Installing collected packages: webdriver-manager\n",
      "Successfully installed webdriver-manager-4.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#%pip install selenium requests pandas beautifulsoup4 webdriver-manager python-dateutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6c7740",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d8d384",
   "metadata": {},
   "source": [
    "# Configuration and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b161ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded. Output directory: data_container/\n"
     ]
    }
   ],
   "source": [
    "# configuration and setup \n",
    "class Config:\n",
    "\n",
    "    # Date range for scraping\n",
    "    START_DATE = \"2023-01-01\"\n",
    "    END_DATE = \"2025-07-14\"\n",
    "    \n",
    "    # Scraping settings\n",
    "    RATE_LIMIT = 2  # seconds between requests\n",
    "    BATCH_SIZE = 10  # races per batch\n",
    "    \n",
    "    # Selenium settings\n",
    "    HEADLESS = True  # Set to False to see browser window\n",
    "    IMPLICIT_WAIT = 10\n",
    "    PAGE_LOAD_TIMEOUT = 30\n",
    "    \n",
    "    # File output settings\n",
    "    OUTPUT_DIR = \"data_container/\"\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(Config.OUTPUT_DIR, exist_ok=True)  # exist_ok make sure not to double the creation of the directory if it already exist \n",
    "print(f\"Configuration loaded. Output directory: {Config.OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158d0966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup webdriver\n",
    "def setup_webdriver():\n",
    "    chrome_options = Options()\n",
    "    \n",
    "    if Config.HEADLESS: # HEADLESS = True from config\n",
    "        chrome_options.add_argument('--headless')\n",
    "    \n",
    "    # Performance options\n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    chrome_options.add_argument(\"--disable-gpu\")\n",
    "    chrome_options.add_argument(\"--window-size=1920,1080\")\n",
    "    chrome_options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    chrome_options.add_experimental_option('useAutomationExtension', False)\n",
    "\n",
    "    # User agent -- pretend to be regular user browser to prevent block/detection\n",
    "    chrome_options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')\n",
    "\n",
    "    # Setup driver\n",
    "    service = Service(ChromeDriverManager().install()) # install the correct chromedriver for browser\n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options) \n",
    "\n",
    "    # Config timeouts\n",
    "    driver.implicitly_wait(Config.IMPLICIT_WAIT) # set wait time for the content to load\n",
    "    driver.set_page_load_timeout(Config.PAGE_LOAD_TIMEOUT) # maximum time allow the page to load\n",
    "\n",
    "    # Hide webdriver property -- hind automation signature to avoid bot detection\n",
    "    driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
    "\n",
    "    return driver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ccdba16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing WebDriver setup...\n",
      "WebDriver setup failed: Could not reach host. Are you offline?\n",
      "Make sure Chrome browser is installed on your system.\n"
     ]
    }
   ],
   "source": [
    "# Test WebDriver setup\n",
    "print(\"Testing WebDriver setup...\")\n",
    "\n",
    "try:\n",
    "    test_driver = setup_webdriver()\n",
    "    print(f\"WebDriver setup successful! Browser: {test_driver.capabilities['browserName']} {test_driver.capabilities['browserVersion']}\")\n",
    "    test_driver.quit()\n",
    "    print(\"WebDriver test completed.\")\n",
    "\n",
    "# python creates a Exception object whenever it encounters an error\n",
    "except Exception as e: \n",
    "    print(f\"WebDriver setup failed: {e}\")\n",
    "    print(\"Make sure Chrome browser is installed on your system.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fe7e6d",
   "metadata": {},
   "source": [
    "# Define scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b80306a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main HKJC Scraper Class\n",
    "class HKJCScraper:\n",
    "    def __init__(self): # when starting a new scraper instance\n",
    "        self.driver = None \n",
    "        self.all_data = [] # start a empty list to collect data\n",
    "        self.processed_count = 0 # counting how many race pages have been processed\n",
    "        self.errors = [] # start a empty list to log errors for debugging\n",
    "\n",
    "    # browser management\n",
    "    def start_browser(self):\n",
    "        \"\"\"Start the browser\"\"\"\n",
    "        if self.driver is None: # check if browser is already running\n",
    "            self.driver = setup_webdriver() # setup the webdriver by using function defined above\n",
    "            print(\"Browser started\")\n",
    "    \n",
    "    def stop_browser(self):\n",
    "        \"\"\"Stop the browser\"\"\"\n",
    "        if self.driver: # is not none means browser is running\n",
    "            self.driver.quit() # close the browser\n",
    "            self.driver = None # reset the driver to None\n",
    "            print(\"Browser stopped\")\n",
    "\n",
    "    # define main scraper\n",
    "    def scrape_single_race(self, date, venue, race_no):\n",
    "        try:\n",
    "            # build the url from info provided\n",
    "            date_str = date.strftime('%Y/%m/%d')\n",
    "            url = f'https://racing.hkjc.com/racing/information/English/Racing/LocalResults.aspx?RaceDate={date_str}&Racecourse={venue}&RaceNo={race_no}'\n",
    "\n",
    "            print(f'scraping: {date.strftime(\"%Y-%m-%d\")}, {venue}, Race:{race_no}')\n",
    "\n",
    "            # get page content\n",
    "            self.driver.get(url)\n",
    "            time.sleep(2) # wait for the page to load\n",
    "            soup = BeautifulSoup(self.driver.page_source, 'html.parser')\n",
    "\n",
    "            # check if race exists (look for results table)\n",
    "            results_table = soup.find('table', class_='table_bd')\n",
    "            if not results_table:\n",
    "                print(f\"No results found for {date.strftime('%Y-%m-%d')}\")\n",
    "                return False\n",
    "\n",
    "            # Extract basic race info\n",
    "            race_info = {\n",
    "                'date': date.strftime('%Y-%m-%d'),\n",
    "                'venue': venue,\n",
    "                'race_no': race_no,\n",
    "                'data_type': 'race_info',\n",
    "                'scrape_time': datetime.now().isoformat()\n",
    "            }\n",
    "\n",
    "            # Try to extract race details by finding 'Class', 'HANDICAP', or 'M' in text\n",
    "            try:\n",
    "                # Find all relevant divs, spans, or table with filters with lambda function, selecting those only with 'Class', 'HANDICAP', or 'M' in text\n",
    "                race_detail_divs = soup.find_all(['div', 'span', 'td'], string = lambda text: text and ('Class' in text or 'HANDICAP' in text or 'M' in text))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
