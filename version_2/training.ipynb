{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "d7364d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostRanker, Pool\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import ndcg_score\n",
    "import warnings\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "0ef957ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore', category = UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "5bc4c3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/cleaned_data_20250930.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "9eef3890",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'], errors = 'coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "a5b20ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporal_cv_split(df, n_splits=5):\n",
    "    df_sorted = df.sort_values('Date')\n",
    "    unique_races = df_sorted['race_index'].unique()\n",
    "    \n",
    "    fold_size = len(unique_races) // (n_splits + 1)\n",
    "    \n",
    "    for i in range(n_splits):\n",
    "        train_end = (i + 1) * fold_size\n",
    "        val_start = train_end\n",
    "        val_end = train_end + fold_size\n",
    "        \n",
    "        train_races = unique_races[:train_end]\n",
    "        val_races = unique_races[val_start:val_end]\n",
    "        \n",
    "        yield train_races, val_races"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94213b3",
   "metadata": {},
   "source": [
    "# spliting train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "45f4a7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-06 00:00:00\n",
      "2025-09-28 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print(df['Date'].min())\n",
    "print(df['Date'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "4754c7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "min_date = pd.to_datetime(df['Date'].min())\n",
    "max_date = pd.to_datetime(df['Date'].max())\n",
    "\n",
    "total_days = (max_date - min_date).days\n",
    "cutoff_days = int(total_days * 0.8)\n",
    "cutoff_date = min_date + pd.Timedelta(days=cutoff_days)\n",
    "\n",
    "train_df = df[df['Date'] <= cutoff_date]\n",
    "test_df = df[df['Date'] > cutoff_date]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "9d14c163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-06 00:00:00\n",
      "2024-09-22 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print(train_df['Date'].min())\n",
    "print(train_df['Date'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "b00a0d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train validation split\n",
    "min_date = pd.to_datetime(train_df['Date'].min())\n",
    "max_date = pd.to_datetime(train_df['Date'].max())\n",
    "\n",
    "total_days = (max_date - min_date).days\n",
    "cutoff_days = int(total_days * 0.8)\n",
    "cutoff_date = min_date + pd.Timedelta(days = cutoff_days)\n",
    "\n",
    "val_df = train_df[train_df['Date'] > cutoff_date]\n",
    "train_df = train_df[train_df['Date'] <= cutoff_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "6742285a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'race_index', 'RaceClass', 'rc', 'track', 'course', 'Dist.',\n",
       "       'track_condition', 'Horse_id', 'Declar.Horse Wt.', 'Act.Wt.',\n",
       "       'gate_position', 'Rtg.', 'age', 'colour', 'sex', 'origin',\n",
       "       'Import type', 'Trainer', 'Jockey', 'Sire', 'Dam', 'Dam sire',\n",
       "       'Finish Time', 'Gear', 'target', 'recent_3_win_rate_horse',\n",
       "       'recent_3_win_rate_jockey', 'recent_5_avg_finish_pos',\n",
       "       'recent_3_consistency', 'jockey_trainer_combo_rate',\n",
       "       'horse_track_distance_rate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672ee36d",
   "metadata": {},
   "source": [
    "# define features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95261d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define features\n",
    "categorical_cols = [\n",
    "    'Dist.', 'track_condition', 'RaceClass', 'Trainer', 'Jockey', 'Dam sire', 'rc', 'track', 'course', \n",
    "    'Import type', 'Sire', 'Dam', 'origin', 'age', 'colour', 'sex'\n",
    "]\n",
    "\n",
    "numerical_cols = [\n",
    "    'Rtg.', 'Act.Wt.', 'Declar.Horse Wt.','recent_3_win_rate_horse',\n",
    "       'recent_3_win_rate_jockey', 'recent_5_avg_finish_pos',\n",
    "       'recent_3_consistency', 'jockey_trainer_combo_rate',\n",
    "       'horse_track_distance_rate'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "58433407",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rn/zdwl9_vx4yz5r87jv7jnztdh0000gn/T/ipykernel_3886/1555292549.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[numerical_cols] = num_imputer.transform(test_df[numerical_cols])\n",
      "/var/folders/rn/zdwl9_vx4yz5r87jv7jnztdh0000gn/T/ipykernel_3886/1555292549.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[col] = test_df[col].astype(str).fillna('unknown')\n",
      "/var/folders/rn/zdwl9_vx4yz5r87jv7jnztdh0000gn/T/ipykernel_3886/1555292549.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[col] = test_df[col].astype(str).fillna('unknown')\n",
      "/var/folders/rn/zdwl9_vx4yz5r87jv7jnztdh0000gn/T/ipykernel_3886/1555292549.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[col] = test_df[col].astype(str).fillna('unknown')\n",
      "/var/folders/rn/zdwl9_vx4yz5r87jv7jnztdh0000gn/T/ipykernel_3886/1555292549.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[col] = test_df[col].astype(str).fillna('unknown')\n",
      "/var/folders/rn/zdwl9_vx4yz5r87jv7jnztdh0000gn/T/ipykernel_3886/1555292549.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[col] = test_df[col].astype(str).fillna('unknown')\n",
      "/var/folders/rn/zdwl9_vx4yz5r87jv7jnztdh0000gn/T/ipykernel_3886/1555292549.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[col] = test_df[col].astype(str).fillna('unknown')\n",
      "/var/folders/rn/zdwl9_vx4yz5r87jv7jnztdh0000gn/T/ipykernel_3886/1555292549.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[col] = test_df[col].astype(str).fillna('unknown')\n",
      "/var/folders/rn/zdwl9_vx4yz5r87jv7jnztdh0000gn/T/ipykernel_3886/1555292549.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[col] = test_df[col].astype(str).fillna('unknown')\n",
      "/var/folders/rn/zdwl9_vx4yz5r87jv7jnztdh0000gn/T/ipykernel_3886/1555292549.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[col] = test_df[col].astype(str).fillna('unknown')\n",
      "/var/folders/rn/zdwl9_vx4yz5r87jv7jnztdh0000gn/T/ipykernel_3886/1555292549.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[col] = test_df[col].astype(str).fillna('unknown')\n",
      "/var/folders/rn/zdwl9_vx4yz5r87jv7jnztdh0000gn/T/ipykernel_3886/1555292549.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[col] = test_df[col].astype(str).fillna('unknown')\n",
      "/var/folders/rn/zdwl9_vx4yz5r87jv7jnztdh0000gn/T/ipykernel_3886/1555292549.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[col] = test_df[col].astype(str).fillna('unknown')\n",
      "/var/folders/rn/zdwl9_vx4yz5r87jv7jnztdh0000gn/T/ipykernel_3886/1555292549.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[col] = test_df[col].astype(str).fillna('unknown')\n",
      "/var/folders/rn/zdwl9_vx4yz5r87jv7jnztdh0000gn/T/ipykernel_3886/1555292549.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[col] = test_df[col].astype(str).fillna('unknown')\n",
      "/var/folders/rn/zdwl9_vx4yz5r87jv7jnztdh0000gn/T/ipykernel_3886/1555292549.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[col] = test_df[col].astype(str).fillna('unknown')\n",
      "/var/folders/rn/zdwl9_vx4yz5r87jv7jnztdh0000gn/T/ipykernel_3886/1555292549.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[col] = test_df[col].astype(str).fillna('unknown')\n"
     ]
    }
   ],
   "source": [
    "num_imputer = SimpleImputer(strategy='median')\n",
    "train_df[numerical_cols] = num_imputer.fit_transform(train_df[numerical_cols])\n",
    "val_df[numerical_cols] = num_imputer.transform(val_df[numerical_cols])\n",
    "test_df[numerical_cols] = num_imputer.transform(test_df[numerical_cols])\n",
    "\n",
    "for col in categorical_cols:\n",
    "    train_df[col] = train_df[col].astype(str).fillna('unknown')\n",
    "    val_df[col] = val_df[col].astype(str).fillna('unknown')\n",
    "    test_df[col] = test_df[col].astype(str).fillna('unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "ac2f534c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df[categorical_cols + numerical_cols]\n",
    "y_train = train_df['target']\n",
    "groups_train = train_df['race_index']\n",
    "\n",
    "X_val = val_df[categorical_cols + numerical_cols]\n",
    "y_val = val_df['target']\n",
    "groups_val = val_df['race_index']\n",
    "\n",
    "X_test = test_df[categorical_cols + numerical_cols]\n",
    "y_test = test_df['target']\n",
    "groups_test = test_df['race_index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "a1ba85a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by groups\n",
    "train_sorted_idx = groups_train.argsort()\n",
    "X_train = X_train.iloc[train_sorted_idx]\n",
    "y_train = y_train.iloc[train_sorted_idx]\n",
    "groups_train = groups_train.iloc[train_sorted_idx]\n",
    "\n",
    "val_sorted_idx = groups_val.argsort()\n",
    "X_val = X_val.iloc[val_sorted_idx]\n",
    "y_val = y_val.iloc[val_sorted_idx]\n",
    "groups_val = groups_val.iloc[val_sorted_idx]\n",
    "\n",
    "test_sorted_idx = groups_test.argsort()\n",
    "X_test = X_test.iloc[test_sorted_idx]\n",
    "y_test = y_test.iloc[test_sorted_idx]\n",
    "groups_test = groups_test.iloc[test_sorted_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86d3a16",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "d0b75b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CatBoost Pools\n",
    "train_pool = Pool(\n",
    "    data=X_train,\n",
    "    label=y_train,\n",
    "    group_id=groups_train,\n",
    "    cat_features=categorical_cols\n",
    ")\n",
    "\n",
    "val_pool = Pool(\n",
    "    data=X_val,\n",
    "    label=y_val,\n",
    "    group_id=groups_val,\n",
    "    cat_features=categorical_cols\n",
    ")\n",
    "\n",
    "test_pool = Pool(\n",
    "    data=X_test,\n",
    "    label=y_test,\n",
    "    group_id=groups_test,\n",
    "    cat_features=categorical_cols\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "d653c44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groupwise loss function. OneHotMaxSize set to 10\n",
      "0:\ttest: 0.3494636\tbest: 0.3494636 (0)\ttotal: 56.7ms\tremaining: 1m 25s\n",
      "100:\ttest: 0.3962826\tbest: 0.4269484 (9)\ttotal: 1.43s\tremaining: 19.9s\n",
      "200:\ttest: 0.3850226\tbest: 0.4269484 (9)\ttotal: 2.84s\tremaining: 18.3s\n",
      "300:\ttest: 0.3862548\tbest: 0.4269484 (9)\ttotal: 4.35s\tremaining: 17.3s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.4269483527\n",
      "bestIteration = 9\n",
      "\n",
      "Shrink model to first 10 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRanker at 0x12c97b4a0>"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model with optimized parameters\n",
    "model = CatBoostRanker(\n",
    "    iterations=1500,\n",
    "    learning_rate=0.01,\n",
    "    depth=6,\n",
    "    loss_function='YetiRank',\n",
    "    eval_metric='NDCG:top=4',\n",
    "    l2_leaf_reg=10,\n",
    "    random_strength=5,\n",
    "    bagging_temperature=2,\n",
    "    has_time=True,\n",
    "    verbose=100,\n",
    "    early_stopping_rounds=300\n",
    ")\n",
    "\n",
    "# Train with validation monitoring\n",
    "model.fit(train_pool, eval_set=val_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "c326cf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "c3cb075e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average NDCG@4 across all races: 0.3838\n",
      "NDCG calculated on 856 races\n",
      "NDCG std: 0.2501\n"
     ]
    }
   ],
   "source": [
    "def calculate_ndcg_per_group(y_true, y_pred, groups, k=4):\n",
    "    \"\"\"\n",
    "    Calculate NDCG per race group and return average\n",
    "    \"\"\"\n",
    "    ndcg_scores = []\n",
    "    unique_groups = np.unique(groups)\n",
    "    \n",
    "    for group_id in unique_groups:\n",
    "        # Get data for this specific race\n",
    "        group_mask = groups == group_id\n",
    "        group_true = y_true[group_mask]\n",
    "        group_pred = y_pred[group_mask]\n",
    "        \n",
    "        # Skip if not enough horses in race for k=4\n",
    "        if len(group_true) < 2:  # Need at least 2 horses to rank\n",
    "            continue\n",
    "            \n",
    "        # Calculate NDCG for this race\n",
    "        try:\n",
    "            race_ndcg = ndcg_score([group_true], [group_pred], k=min(k, len(group_true)))\n",
    "            ndcg_scores.append(race_ndcg)\n",
    "        except:\n",
    "            # Skip problematic races (e.g., all zeros)\n",
    "            continue\n",
    "    \n",
    "    if len(ndcg_scores) == 0:\n",
    "        return 0.0\n",
    "        \n",
    "    return np.mean(ndcg_scores), ndcg_scores\n",
    "\n",
    "# CORRECT EVALUATION:\n",
    "avg_ndcg, individual_ndcg = calculate_ndcg_per_group(y_test, y_pred, groups_test, k=4)\n",
    "print(f\"Average NDCG@4 across all races: {avg_ndcg:.4f}\")\n",
    "print(f\"NDCG calculated on {len(individual_ndcg)} races\")\n",
    "print(f\"NDCG std: {np.std(individual_ndcg):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270aa74f",
   "metadata": {},
   "source": [
    "# saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "4a235f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model(\n",
    "    fname = '../model/catboost_ranker.cbm',\n",
    "    format = 'cbm'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "0fe0b62b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../model/num_imputer.pkl']"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(num_imputer, '../model/num_imputer.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21301eb",
   "metadata": {},
   "source": [
    "# further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b99c6c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERFORMANCE BY RACE CHARACTERISTICS:\n",
      "==================================================\n",
      "By Race Class:\n",
      "                mean       std  count\n",
      "race_class                           \n",
      "1           0.464241  0.188248      8\n",
      "2           0.442483  0.238687     56\n",
      "3           0.427184  0.237781    243\n",
      "3R          0.139595       NaN      1\n",
      "4           0.427368  0.240003    389\n",
      "4R          0.254241  0.145738      4\n",
      "4YO         0.208491  0.086757      3\n",
      "5           0.387695  0.249550    116\n",
      "G1          0.465919  0.304390     12\n",
      "G2          0.577168  0.221679      7\n",
      "G3          0.324665  0.277465     12\n",
      "GRIFFIN     0.648099  0.243188      5\n",
      "\n",
      "By Distance:\n",
      "              mean       std  count\n",
      "distance                           \n",
      "1000      0.429561  0.261763     78\n",
      "1200      0.433062  0.237072    342\n",
      "1400      0.445232  0.245586    147\n",
      "1600      0.398353  0.249318     64\n",
      "1650      0.415151  0.237003    133\n",
      "1800      0.364238  0.249060     58\n",
      "2000      0.399064  0.235734     20\n",
      "2200      0.393517  0.215073     11\n",
      "2400      0.286610  0.181937      3\n",
      "\n",
      "By Track:\n",
      "           mean       std  count\n",
      "track                           \n",
      "AWT    0.417978  0.219151     86\n",
      "Turf   0.423534  0.244705    770\n"
     ]
    }
   ],
   "source": [
    "def analyze_performance_by_race_type(test_df, y_test, y_pred, groups_test, individual_ndcg):\n",
    "    \"\"\"\n",
    "    Understand which race types your model handles best/worst\n",
    "    \"\"\"\n",
    "    \n",
    "    results_by_race = []\n",
    "    \n",
    "    for i, group_id in enumerate(np.unique(groups_test)):\n",
    "        group_mask = groups_test == group_id\n",
    "        race_data = test_df[group_mask].iloc[0]  # Get race characteristics\n",
    "        \n",
    "        race_result = {\n",
    "            'race_index': group_id,\n",
    "            'ndcg_score': individual_ndcg[i] if i < len(individual_ndcg) else 0,\n",
    "            'race_class': race_data['RaceClass'],\n",
    "            'distance': race_data['Dist.'],\n",
    "            'track': race_data['track'],\n",
    "            'field_size': np.sum(group_mask)\n",
    "        }\n",
    "        results_by_race.append(race_result)\n",
    "    \n",
    "    race_analysis = pd.DataFrame(results_by_race)\n",
    "    \n",
    "    print(\"PERFORMANCE BY RACE CHARACTERISTICS:\")\n",
    "    print(\"=\"*50)\n",
    "    print(\"By Race Class:\")\n",
    "    print(race_analysis.groupby('race_class')['ndcg_score'].agg(['mean', 'std', 'count']))\n",
    "    \n",
    "    print(\"\\nBy Distance:\")\n",
    "    print(race_analysis.groupby('distance')['ndcg_score'].agg(['mean', 'std', 'count']))\n",
    "    \n",
    "    print(\"\\nBy Track:\")\n",
    "    print(race_analysis.groupby('track')['ndcg_score'].agg(['mean', 'std', 'count']))\n",
    "    \n",
    "    return race_analysis\n",
    "\n",
    "# Run this analysis to understand your model's strengths/weaknesses\n",
    "race_analysis = analyze_performance_by_race_type(test_df, y_test, y_pred, groups_test, individual_ndcg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1bc8f1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8f6c148b",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = model.get_feature_importance(data = train_pool)\n",
    "feature_names = model.feature_names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ea6051eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_importance = feature_importance.sum()\n",
    "cumulative_importance = 0\n",
    "important_features = []\n",
    "for feat, imp in sorted(zip(feature_names, feature_importance), key=lambda x: x[1], reverse=True):\n",
    "    cumulative_importance += imp\n",
    "    important_features.append(feat)\n",
    "    if cumulative_importance / total_importance >= 0.9:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9cf64bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Jockey', 'horse_track_distance_rate', 'recent_5_avg_finish_pos']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "important_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b077dd",
   "metadata": {},
   "source": [
    "# sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "e0a3b073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1070925  2070925  3070925  4070925  5070925  6070925  7070925  8070925\n",
      "  9070925 10070925]\n"
     ]
    }
   ],
   "source": [
    "print(groups_test.unique()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "c9ea9516",
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_race = 5070925\n",
    "\n",
    "race_mask = (groups_test == specific_race)\n",
    "horse_ids = test_df.loc[race_mask, 'Horse_id']\n",
    "\n",
    "# Get the horse info, true placing, predicted scores for the race\n",
    "race_true = y_test[race_mask]\n",
    "race_pred = y_pred[race_mask]\n",
    "race_data = X_test[race_mask]\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Horse_id': horse_ids,\n",
    "    'True_Score': race_true.values,\n",
    "    'Predicted_Score': race_pred\n",
    "})\n",
    "\n",
    "# Sort by predicted score (descending: highest score means better rank)\n",
    "comparison_df_sorted_by_pred = comparison_df.sort_values(by='Predicted_Score', ascending=False)\n",
    "\n",
    "# Sort by true rank (ascending: 1 is best rank)\n",
    "comparison_df_sorted_by_true = comparison_df.sort_values(by='True_Score', ascending= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "78f133b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted by Predicted Ranking Scores:\n",
      "      Horse_id  True_Score  Predicted_Score\n",
      "40701     G427    0.000000         0.030592\n",
      "14783     H459    1.000000         0.021121\n",
      "1218      J542    0.606531        -0.000800\n",
      "43349     J392    0.000000        -0.002190\n",
      "51182     K420    0.000000        -0.011262\n",
      "25952     K273    0.223130        -0.015843\n",
      "4109      K039    0.000000        -0.018184\n",
      "35140     K305    0.000000        -0.019911\n",
      "33022     J315    0.367879        -0.020000\n",
      "7397      K364    0.000000        -0.021622\n",
      "26639     J444    0.000000        -0.025355\n",
      "30712     J152    0.000000        -0.025868\n",
      "47773     J529    0.000000        -0.028471\n",
      "15554     K299    0.000000        -0.031423\n",
      "\n",
      "Sorted by True Ranking:\n",
      "      Horse_id  True_Score  Predicted_Score\n",
      "14783     H459    1.000000         0.021121\n",
      "1218      J542    0.606531        -0.000800\n",
      "33022     J315    0.367879        -0.020000\n",
      "25952     K273    0.223130        -0.015843\n",
      "4109      K039    0.000000        -0.018184\n",
      "7397      K364    0.000000        -0.021622\n",
      "15554     K299    0.000000        -0.031423\n",
      "26639     J444    0.000000        -0.025355\n",
      "30712     J152    0.000000        -0.025868\n",
      "35140     K305    0.000000        -0.019911\n",
      "40701     G427    0.000000         0.030592\n",
      "43349     J392    0.000000        -0.002190\n",
      "47773     J529    0.000000        -0.028471\n",
      "51182     K420    0.000000        -0.011262\n"
     ]
    }
   ],
   "source": [
    "print(\"Sorted by Predicted Ranking Scores:\")\n",
    "print(comparison_df_sorted_by_pred)\n",
    "\n",
    "print(\"\\nSorted by True Ranking:\")\n",
    "print(comparison_df_sorted_by_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a43368",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scraping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
